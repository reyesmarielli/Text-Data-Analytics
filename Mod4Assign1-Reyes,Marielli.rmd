---
output:
  word_document: default
  html_document: default
---
###Module 4 - Assignment3
####Reyes, Marielli Nicole

The libraries used for the assignment are: 
```{r}
library(tidyverse) 
library(ggplot2) 
library(gridExtra)
library(tidytext) 
library(stringr)
library(wordcloud2)
```


The prince dataset was read into R.
```{r}
prince_original <- read.csv("prince_text.csv", stringsAsFactors = FALSE)
```


The dataset consists of 824 observations of 20 variables. 
```{r}
glimpse(prince_original)
names(prince_original)
```


Relevant columns were selected and the column "text" was changed to "lyrics."
```{r}
prince <-prince_original %>%
 select (lyrics = text, song, year, album, peak, US.Pop, US.R.B)
```


A new column, decade, was created. 
```{r}
prince <- prince %>%
 mutate(decade =
 ifelse(prince$year %in% 1978:1979, "1970s",
 ifelse(prince$year %in% 1980:1989, "1980s",
 ifelse(prince$year %in% 1990:1999, "1990s",
 ifelse(prince$year %in% 2000:2009, "2000s",
 ifelse(prince$year %in% 2010:2015, "2010s",
 "NA"))))))
```


Column chart_level was also created. 
```{r}
prince <- prince %>%
 mutate(chart_level =
 ifelse(prince$peak %in% 1:10, "Top 10",
 ifelse(prince$peak %in% 11:100, "Top 100", "Uncharted")))
```


The dataset now has 824 observations of 9 variables. 
```{r}
names(prince)
glimpse(prince)
```


Contractions were removed.
```{r}
fix.contractions <- function(doc) {
 doc <- gsub("won't", "will not", doc)
 doc <- gsub("can't", "can not", doc)
 doc <- gsub("n't", " not", doc)
 doc <- gsub("'ll", " will", doc)
 doc <- gsub("'re", " are", doc)
 doc <- gsub("'ve", " have", doc)
 doc <- gsub("'m", " am", doc)
 doc <- gsub("'d", " would", doc)
 doc <- gsub("'s", "", doc)
 return(doc)
}

prince$lyrics <- sapply(prince$lyrics, fix.contractions)
```



Lyrics was transformed into tidy data and text was prepared for analysis by removing the stop words, undesirable words, numbers, whitespaces, and special characters.
```{r}
tidy_prince = prince %>%
 unnest_tokens("word", lyrics)

data("stop_words")
undesirable_words <- c("prince", "chorus", "repeat", "lyrics",
 "theres", "bridge", "fe0f", "yeah", "baby",
"alright", "wanna", "gonna", "chorus", "verse",
"whoa", "gotta", "make", "miscellaneous", "2",
"4", "ooh", "uurh", "pheromone", "poompoom", "3121",
"matic", " ai ", " ca ", " la ", "hey", " na ",
" da ", " uh ", " tin ", " ll", "transcription",
"repeats")
tidy_prince<-tidy_prince%>%
 filter(!word %in% undesirable_words)%>%
 anti_join(stop_words)%>%
 filter(!nchar(word) < 3,
 !str_detect(word, "^\\b\\d+\\b"),
 !str_detect(word, "\\s+"),
 !str_detect(word, "[^a-zA-Z]")) 
```


The most frequently used word is "love".
```{r}
tidy_prince %>%
 count(word, sort = TRUE) 
```

In order to examine lexicons, new_sentiments dataframe was created. 
```{r}
new_sentiments <- sentiments %>% 
 filter(lexicon != "loughran") %>% 
 mutate( sentiment = ifelse(lexicon == "afinn" & score >= 0, "positive",
 ifelse(lexicon == "afinn" & score < 0,
 "negative", sentiment))) %>%
 group_by(lexicon) %>%
 mutate(words_in_lexicon = n_distinct(word)) %>%
 ungroup()
```


The lexicon was matched. 
```{r}
tidy_prince %>%
 mutate(words_in_lyrics = n_distinct(word)) %>%
 inner_join(new_sentiments) %>%
 group_by(lexicon, words_in_lyrics, words_in_lexicon) %>%
 summarise(lex_match_words = n_distinct(word)) %>%
 ungroup() %>%
 mutate(total_match_words = sum(lex_match_words), #Not used but good to ha  ve
 match_ratio = lex_match_words / words_in_lyrics) %>%
 select(lexicon, lex_match_words, words_in_lyrics, match_ratio) 
```


Sentiment analysis was implemented.
```{r}
prince_sentiment <- tidy_prince %>%
 inner_join(get_sentiments("nrc"))
```


A new column, song_total, was created and sentiment analysis was implemented.
```{r}
prince_sentiment_song <- tidy_prince %>%
 group_by(song) %>%
 mutate(song_total=n()) %>%
 ungroup() %>%
 inner_join(get_sentiments("nrc"))

```

Negative words were examined.
```{r}
prince_sentiment_song %>%
 count(song, sentiment, song_total) %>%
 mutate(percent=n/song_total) %>%
 filter(sentiment %in% c("negative")) %>%
 arrange(desc(percent))
```


Positive words were examined.
```{r}
prince_sentiment_song %>%
 count(song, sentiment, song_total) %>%
 mutate(percent=n/song_total) %>%
 filter(sentiment %in% c("positive")) %>%
 arrange(desc(percent))
```

Words were assessed to see which ones contributed most to sentiment scores. 
```{r}
prince_sentiment_song %>%
 count(word,sentiment) %>%
 group_by(sentiment) %>%
 top_n(10,n) %>%
 ungroup() %>%
 mutate(word = reorder(word, n)) %>%
 ggplot(aes(word,n, fill=sentiment)) +
 geom_col(show.legend = FALSE) +
 facet_wrap(~ sentiment, scales = "free") +
 coord_flip()
```

Filter were implemented on negative words.
```{r}
prince_sentiment_song %>%
filter((sentiment %in% c("negative"))) %>%
count(word, song) %>%
group_by(song) %>%
top_n(10,n) %>%
ungroup() 

#ggplot(aes(word, n, fill = song)) +
#geom_col(show.legend = FALSE) +
# scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
#facet_wrap(~ song, nrow = 2, scales = "free") +
# coord_flip()
```

Analysis was broken down to chart level by using Bing lexicon. It can be seen from the results that the charted songs are more positive than the uncharted. However, the difference in values are not big or significant so this claim cannot be supported.
```{r}
prince_bing <- tidy_prince %>%
 inner_join(get_sentiments("bing"))

prince_polarity_chart <- prince_bing %>%
 count(sentiment, chart_level) %>%
 spread(sentiment, n, fill = 0) %>%
 mutate(polarity = positive - negative,
 percent_positive = positive / (positive + negative) * 100)

prince_polarity_chart

```

Sentiment changes over time was analyzed. The trends show that there are more negative polarity over time. 
```{r}
prince_polarity_year <- prince_bing %>%
 count(sentiment, year) %>%
 spread(sentiment, n, fill = 0) %>%
 mutate(polarity = positive - negative,
 percent_positive = positive / (positive + negative) * 100)

prince_polarity_year

my_colors <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#D55E00", "#D65E00")

theme_lyrics <- function()
{
 theme(plot.title = element_text(hjust = 0.5),
 axis.text.x = element_blank(),
 axis.ticks = element_blank(),
 panel.grid.major = element_blank(),
 panel.grid.minor = element_blank(),
 legend.position = "none")
}
polarity_over_time <- prince_polarity_year %>%
 ggplot(aes(year, polarity, color = ifelse(polarity >= 0,my_colors[5],my_colors[4]))) +
 geom_col() +
 geom_smooth(method = "loess", se = FALSE) +
 geom_smooth(method = "lm", se = FALSE, aes(color = my_colors[1])) +
 theme_lyrics() + theme(plot.title = element_text(size = 11)) +
 xlab(NULL) + ylab(NULL) +
 ggtitle("Polarity Over Time")
relative_polarity_over_time <- prince_polarity_year %>%
 ggplot(aes(year, percent_positive , color = ifelse(polarity >= 0,my_colors[5],my_colors[4]))) +
 geom_col() +
 geom_smooth(method = "loess", se = FALSE) +
 geom_smooth(method = "lm", se = FALSE, aes(color = my_colors[1])) +
 theme_lyrics() + theme(plot.title = element_text(size = 11)) +
 xlab(NULL) + ylab(NULL) +
 ggtitle("Percent Positive Over Time")

grid.arrange(polarity_over_time, relative_polarity_over_time, ncol = 2)

```

Through this assignment, I learned how to determine which information in my data are associated with positive and negative words. In this assisngment, we focused on the songs data. By applying sentiment analysis, it was revealed that Prince's top 3 songs that are associated with negative words are "Get Some Solo", "Crazy You", and "Controversy". On the other hand, his top 3 songs that are associated with positive words are "We Can Work It Out", "DMSR", and "Electric Intercourse". I was also able to assess which words contributed most to sentiment scores and the top words are "anger", "anticipation", "disgust", "fear", "joy", "negative", "positive", "sadness", "surprise", and "trust". Further, it was revealed from the analysis that the charted songs were more positive than the uncharted. The difference, however, is not that big or significant, so it is not sufficient to assume this. Lastly, the sentiment changes over time showed that negative polarity is more prevalent throughout the years. This is an interesting finding and if given a chance to analyze this dataset some more in the future, I would like to know if some words are correlated or if some words co-occur or follow some words. 