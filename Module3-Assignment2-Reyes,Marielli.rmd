###Module 3 - Assignment 2
####Reyes, Marielli Nicole
####04/07/2019

The packages used for this assignment:
```{r}
library(dplyr) 
library(ggplot2) 
library(tidytext) 
```

The prince_text dataset was read into the prince data frame. 
```{r}
prince_original = read.csv("prince_text.csv", stringsAsFactors = FALSE)
```


There are a total of 824 observation of 20 variables. 
```{r}
names(prince_original)
glimpse(prince_original)
```

The column "text" was renamed to "lyrics", and only relevant columns were selected for the assignment. 
```{r}
prince = prince_original %>%
  select(lyrics = text, song, year, album, peak, US.Pop, US.R.B)
```


The decade and chart_level columns were created. 
```{r}
prince <- prince %>%
 mutate(decade =
 ifelse(prince$year %in% 1978:1979, "1970s",
 ifelse(prince$year %in% 1980:1989, "1980s",
 ifelse(prince$year %in% 1990:1999, "1990s",
 ifelse(prince$year %in% 2000:2009, "2000s",
 ifelse(prince$year %in% 2010:2015, "2010s",
 "NA"))))))

prince <- prince %>%
 mutate(chart_level =
 ifelse(prince$peak %in% 1:10, "Top 10",
 ifelse(prince$peak %in% 11:100, "Top 100", "Uncharted")))
```


After choosing the relevent columns for the assignment, and creating two new columns, decade and chart_level, the prince data frame now consists of 824 observations of 9 variables.
```{r}
names(prince)
```

Contractions were removed. 
```{r}
fix.contractions <- function(doc) {
 doc <- gsub("won't", "will not", doc)
 doc <- gsub("can't", "can not", doc)
 doc <- gsub("n't", " not", doc)
 doc <- gsub("'ll", " will", doc)
 doc <- gsub("'re", " are", doc)
 doc <- gsub("'ve", " have", doc)
 doc <- gsub("'m", " am", doc)
 doc <- gsub("'d", " would", doc)
 doc <- gsub("'s", "", doc)
 return(doc)
}

prince$lyrics <- sapply(prince$lyrics, fix.contractions)
```


Lyrics was transformed into tidy data and text was prepared for analysis by removing the stop words, undesirable words, numbers, whitespaces, and special characters.
```{r}
tidy_prince = prince %>%
 unnest_tokens("word", lyrics)

data("stop_words")
undesirable_words <- c("prince", "chorus", "repeat", "lyrics", "theres", "bridge", "fe0f", "yeah", "baby","alright", "wanna", "gonna", "chorus", "verse","whoa", "gotta", "make", "miscellaneous", "2","4", "ooh", "uurh", "pheromone", "poompoom", "3121","matic", " ai ", " ca ", " la ", "hey", " na "," da ", " uh ", " tin ", " ll", "transcription","repeats")
tidy_prince<-tidy_prince%>%
 filter(!word %in% undesirable_words)%>%
 anti_join(stop_words)%>%
 filter(!nchar(word) < 3,
 !str_detect(word, "^\\b\\d+\\b"),
 !str_detect(word, "\\s+"),
 !str_detect(word, "[^a-zA-Z]")) 
```

The chart below shows that the top word used most frequently in Prince's lyrics is love, which was used 1,937 times. It is followed by time, girl, stop, and dance. 
```{r}
my_colors <- c("#E69F00", "#56B4E9", "#009E73", "#CC79A7", "#D55E00", "#D65E00")

tidy_prince %>%
 count(word, sort = TRUE) %>%
 top_n(10) %>%
 ungroup() %>%
 mutate(word = reorder(word, n)) %>%
 ggplot() +
 geom_col(aes(word, n), fill = my_colors[4]) +
 xlab("") +
 ylab("Song Count") +
 ggtitle("Most Frequently Used Words in Prince Lyrics") +
 coord_flip()
```


```{r}
tidy_prince %>% 
  count(word) %>% 
  arrange(desc(n))
```
  
  
A wordcloud of the most frequently used words was created.  
```{r}
prince_words_counts <- tidy_prince %>%
 count(word, sort = TRUE)

wordcloud2(prince_words_counts[1:300, ], size = .5)
```

The chart below shows song trends for Prince over time. During the 1970S, majority of his songs didn't reach the Top 10. In the 80s and 90s, however, his popularity peaked and several of his songs became part of the Top 10. Then, in the 2000s, his songs became less popular but some of his songs were still part of the Top 10. 
```{r}
charted_songs_over_time <- tidy_prince %>%
 filter(peak > 0) %>%
 group_by(decade, chart_level) %>%
 summarise(number_of_songs = n())

charted_songs_over_time %>%
 ggplot() +
 geom_bar(aes(x = decade, y = number_of_songs,
 fill = chart_level), stat = "identity") +
 labs(x = NULL, y = "Song Count") +
 ggtitle("Charted Songs")
```
  
The charts below show that some words are more popular in songs that reached the charts compared to uncharted songs. The top 2 words remained the same whether the songs were part of the charts or not, but some words such as world, hot, and party, were popular in the Top 10 but not in uncharted songs. 
```{r}
popular_words <- tidy_prince %>%
 group_by(chart_level) %>%
 count(word, chart_level, sort = TRUE) %>%
 top_n(10) %>%
 ungroup() %>%
 arrange(chart_level,n) %>%
 mutate(row = row_number())

popular_words %>%
 ggplot(aes(row, n, fill = chart_level)) +
 geom_col(show.legend = NULL) +
 labs(x = NULL, y = "Song Count") +
 ggtitle("Popular Words by Chart Level") +
 facet_wrap(~chart_level, scales = "free") +
 scale_x_continuous( # This handles replacement of row
 breaks = popular_words$row, # notice need to reuse data frame
 labels = popular_words$word) +
 coord_flip()

```


The charts below exhibit interesting results. The td-idf gave different perspectives on potentially important words. Through td-idf, less weight was put on commonly used words so focus was directed to words that may be deemed important but were used less compared to others. Now, the top word for the songs that reached the Top 10 is purple. It is known by many that one of Prince's most popular songs is Purple Rain, and if td-idf wasn't utilized,the word purple will be overlooked because it was used less frequently compared to other words. Thus, an important word might have been ignored if td-idf was not used.
```{r}
popular_tfidf_words <- prince %>%
 unnest_tokens(word, lyrics) %>%
 distinct() %>%
 filter(!word %in% undesirable_words) %>%
 filter(nchar(word) > 3) %>%
 count(chart_level, word, sort = TRUE) %>%
 ungroup() %>%
 bind_tf_idf(word, chart_level, n)

head(popular_tfidf_words)

top_popular_tfidf_words <- popular_tfidf_words %>%
 arrange(desc(tf_idf)) %>%
 mutate(word = factor(word, levels = rev(unique(word)))) %>%
 group_by(chart_level) %>%
 slice(seq_len(8)) %>%
 ungroup() %>%
 arrange(chart_level, tf_idf) %>%
 mutate(row = row_number())

top_popular_tfidf_words %>%
 ggplot(aes(x = row, tf_idf,
 fill = chart_level)) +
 geom_col(show.legend = NULL) +
 labs(x = NULL, y = "TF-IDF") +
 ggtitle("Important Words using TF-IDF by Chart Level") +
 facet_wrap(~chart_level, ncol = 3, scales = "free") +
 scale_x_continuous( # This handles replacement of row
 breaks = top_popular_tfidf_words$row, # notice need to reuse data frame
 labels = top_popular_tfidf_words$word) +
 coord_flip()

```
  
Upon initial analysis of the data, it showed that the top word that was used in Prince's songs was love, followed by time, girl, stop, and dance. Trends for his songs over time were also examined and it was revealed that in the 70s, only a few of his songs entered the Top 10 charts. However, in the 80s and 90s, his popularity seemed to peak and majority of his songs were part of the Top 10. Moreover, further analysis showed that the top 2 words remained the same whether the songs were part of the charts or not, but some words such as world, hot, and party, were popular in the Top 10 but not in uncharted songs. In addition, td-idf was used on the data so that more weight will be put on words less frequently used but may be important to the analysis. The results showed interesting insights; the td-idf gave different perspectives on potentially important words. It was shown that
the top word now is purple. Purple rain is one of Prince's most popular songs and the word purple may have been overlooked if td-idf wasn't used since the word was not used as frequently compared to other words. I have learned that the data may show different results based on the different perspectives that are being examined so it is important to be thorough and to analyze the data from different viewpoints. In the future analysis of 
this data, I would also like to know the correlation of the words. I want to know if some words tend to co-occur or if some words tend to follow other words.   